[
["index.html", "Welcome", " Welcome The purpose of this guidebook is to provide a brief introduction to performing statistical analysis in R. It is assumed that the reader is knowledgeable about statistical analysis and is selecting the appropriate statistical model for whatever research question they would like to answer, but they are unsure of how to perform the analysis in R. Consequently, statistical theory will not be covered in this book. It is also assumed that the reader is unfamiliar with programming languages and concepts. Before delving into the various statistical models, a concise overview of programming concepts will be covered, so that hopefully the reader will feel comfortable with modifying and extending on example code to suit their analytic endeavors. Chapters 1 and 2 will cover downloading and describing R and the RStudio IDE, and programming basics, such as variable types and data types, objects and assignments, and functions and arguments. Chapters 3 and 4 will cover installing/loading packages and reading/writing data. Chapters 5 and 6 will cover formatting data, descriptive statistics, and visualizing data. Chapters 7-13 will cover various statistical models from the General Linear Model (GLM) framework. In the simplest form, GLM is described as: DATA = MODEL + ERROR. "],
["statistical-model-flowchart.html", "Statistical Model Flowchart", " Statistical Model Flowchart Above is a statistical test flowchart that can help you decide which model is most appropriate for your analysis. Again, this book will not cover statistical theory or when it’s most appropriate to select a certain model, but this flowchart can still serve as a handy reference while reading this book. "],
["functions-list.html", "Functions List", " Functions List # GET HELP ON TOPICS / WITH FUNCTIONS help() # INSTALL PACKAGES install.packages() # LOAD PACKAGES library() # PRINT FIRST FEW ROWS OF DATA head() # PRINT LAST FEW ROWS OF DATA tail() # PRINT STRUCTURE OF DATA str() # DESCRIPTIVE STATISTICS mean() sd() summary() cor() var() is.na() # CORRELATION MATRIX rcorr() # Package required: Hmisc # PAIRWISE PARTIAL CORRELATION ppcor::pcor() # Package required: ppcor # VISUALIZE DATA plot() hist() # SHAPIRO-WILK NORMALITY TEST shapiro.test() # LINEAR MODEL lm() # STUDENT&#39;S T-TEST t.test() # ANALYSIS OF DATA FROM FACTORIAL EXPERIMENTS ezANOVA() # Package requried: ez # ANALYSIS OF VARIANCE (MODEL COMPARISON) aov() "],
["resources.html", "Resources", " Resources Link Description Swirl Swirl is an R package that you can use to learn R in R. StackOverflow Need help with R? Stackoverflow is a website where you can post programming related questions Quick R by Datacamp Quick R by Datacamp is a webpage where the content is very simmilar to that of this guidebook: short and sweet, but still covering everything from install R to statistics. R Programming for Data Science R Programming for Data Science is a comprehensive introduction to R and data analysis. "],
["getting-started-with-r.html", "1 Getting Started with R What is R? Installing R What is RStudio? Installing RStudio Opening R or RStudio The RStudio Layout Following Along Opening a Script Saving a Script", " 1 Getting Started with R This chapter will walk through the steps of getting started with R and RStudio. At the end of the chapter, we’ll provide a link where you can download a folder that includes all of the code and data that’s used in this guidebook. What is R? R is an open-source, free software environment for data manipulation and statistical computing. Here is an excerpt from the R website (https://www.r-project.org): The term “environment” is intended to characterize R as a fully planned and coherent system, rather than an incremental accretion of very specific and inflexible tools, as is frequently the case with other data analysis software. A programming language offers more flexibility than other data analysis tools like Excel and SPSS, but the benefit of flexibility comes with the cost of complexity. The learning curve of R is steeper than Excel and SPSS, but once you get the hang of it, R can streamline and simplify many tasks. Have you ever needed to copy and paste many data files together into one “master” file? This method is both error-prone and time-consuming. A task like this can be accomplished in a few lines of code in R, and the code can then used as a template for performing the same kind of task in the future. This is just one example, but R can be used for many other time-consuming tasks like this. The sky is the limit! Installing R Step 1 Go to the R website (https://www.r-project.org/) and click on the download R link that’s circled below. Step 2 You’ll then be redirected to a page that looks like this. If you you scroll down you’ll see several USA locations listed. Click on one of those links (it doesn’t matter which one you choose. For example, I chose the St. Louis location). Step 3 Now click on the download link that is relevant to your operating system. Step 4: Mac users If you’re a mac user, you’ll see this screen next. The version of R you download will depend on which version of software your mac is running. At the time of writing this, the latest R release is R 4.0.0 which is for mac 10.13 OS (High Sierra) and higher. If you have an older version of mac software, you can download an older version of R from the same page. Step 4: Windows users If you’re a windows user you’ll see this screen next, where you’ll want to click on the “install R for the first time” link. You can then download R by clicking on this link. The exact version will likely be different than the one shown here. What is RStudio? Simply put, RStudio IDE is an environment that makes working with R much less painful. “IDE” stands for integrated development environment. Without RStudio, R looks something like this: As you can see it’s a disorganized mess. The RStudio IDE cleans up the R interface so that it’s much cleaner and easier to work with, like this: You don’t need to use RStudio, but we highly recommend that you do because it significantly improves the user experience. Installing RStudio Go to the RStudio website (https://rstudio.com/) and click the download button. Then scroll down and click on the download link that is relevant to your operating system. Opening R or RStudio If you decided not to download RStudio, then you’ll work with R by opening the R application. It’s perfectly fine to do this, but just know that you’ll be on your own! The rest of this book will assume you’ve installed RStudio, and we’ll occasionally make references that are specific to the RStudio interface. If you downloaded RStudio, you’ll work with R by opening RStudio. In this case, you should not open R, because RStudio is simply an interface for R; by using RStudio you are simultaneously using R. So, if you were to open both R and RStudio, you would be starting two separate R sessions, which is not what you want to do. Hopefully that makes sense. Now would be a good time to open RStudio and start following along. The RStudio Layout By default, RStudio uses the 4 pane layout shown below. Pane A: This is where you write your scripts. You can think of a script like a word document, where you can write up an analysis and then save it for later. Pane B: This is where your code is “analyzed”, and specifically it is analyzed under the Console tab (you can ignore the Terminal tab). For example, if you wanted to calculate the mean of 3 numbers, like this mean(c(12, 32, 15)), the result, 19.7, would be displayed in this pane under the Console tab. You can also write code here. For example, you could write mean(c(12, 32, 15)) directly into the console (instead of in Pane A), but keep in mind that any code that is typed here will not be saved. Pane C: This pane has several tabs, but the only one that really matters is the Enironment tab (if you don’t see a Build or Git tab, that’s okay). The Environment tab is where you can view your data and the objects you create, which will make more sense as you progress through the book. Pane D: In this pane you can view files, plots, install packages, get help with R functions and more. Following Along We wanted to make it as easy as possible to follow along with this guidebook, so we created a folder that contains all of the data and code that’s used throughout the chapters, which can be downloaded here. After clicking on the link, you should see a page that has a green Clone or download button, shown below. You can then click on the dropdown arrow on the green button and click Download ZIP. Next, find the folder on your computer, unzip it, move it to a convenient location (such as your Desktop) and then open the file within the folder that ends with the extension .Rproj. Opening a Script After you open the Rproj file, Saving a Script "],
["programming-101.html", "2 Programming 101 Running R Code R is a calculator Objects and Assignment Variable Types Data Types Functions and Arguments", " 2 Programming 101 The goal of this chapter is not to turn you into an R programmer, but to cover the most important programming concepts so that you feel more comfortable using R and are able to get up and running with your analyses as fast as possible. Running R Code The rest of this booklet will contain code blocks that look like this: # This is a code block, and this is an example of a comment. # You can comment your script by using the hashtag. # That way you can make notes to yourself and keep track of what your code # is doing at each step. You can copy and paste the code within the blocks to your R session to try it out for yourself; but the code above is just a comment so it won’t do anything exciting! The code blocks will often (but not always) have some sort of output printed directly below them so that you can see the results. For example: mean(1:10) [1] 5.5 In the example above, the code block consisted of code that calculated the mean of the numbers 1 through 10, and the results were printed directly below. Notice how the output is printed in black font, which is how you can distinguish the code blocks from the output blocks. You can “run” a line of code in R by pressing Cmd + Enter on a Mac and Ctr + Enter on a Windows. For example, if you wanted to know what 75 times 82 is, you could type 75 * 82 into your script and “run” the code by using Cmd + Enter or Ctr + Enter to get the answer. Or, if you’re typing code directly into the console, you can run the code by hitting Enter. R is a calculator Try out R’s calculator functionality by copying and pasting the code below into your R session. 21 + 21 # Addition 43 - 20 # Subtraction 4 * 4 # Multiplication 45 / 3 # Division 2 ^ 3 # Exponentiation sqrt(16) # Square root # R follows PEMDAS rules (((3 + 2)^2) + (10 * 2)) - 4 (3 + 2)^2 + 10 * 2 - 4 Objects and Assignment One of the most basic programming concepts is assignment. Let’s say we want the letter x to refer to the value 5. You can do this by assigning x to the value 5 with the assignment operator, &lt;-, or with the equal sign operator, =: x &lt;- 5 x = 5 In both of these examples the result is the same: x is now assigned to the value 5. It’s a matter of personal preference which operator you’d like to use (&lt;- or =), but it’s best to be consistent to make your script more readable. x is now considered an object. An object is a name used to reference a value or set of values. The object x refers to the value 5. Instead of just assigning the number 5 to x, we could perform several calculations and then assign the result to an object, like so: x &lt;- sqrt(34 + ((12 * 2)^3 - 5)) x # typing x by itself will print the value to the concole [1] 117.6988 The object x no longer refers to 5. We overwrote x and assigned it to a new value, ~117.7. When analyzing data, you’ll likely need transform the data before you can run statistical tests. You can accomplish this by transforming the data and then saving the data as a new object. Let’s look at one more example. head(iris) # The head() function prints the first few observations from the dataset Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa Here’s one of R’s built-in datasets, which is called iris and consists of 3 flower species (setosa, virginica, versicolor) and their their petal characteristics. Let’s say we only wanted to include virginica flowers in our analysis. subset(iris, Species == &quot;virginica&quot;) The code above filters the data to include only virginica plants, but we didn’t assign it to an object so we have no way of referencing our filtered data. iris_virginica &lt;- subset(iris, Species == &quot;virginica&quot;) head(iris_virginica) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 101 6.3 3.3 6.0 2.5 virginica 102 5.8 2.7 5.1 1.9 virginica 103 7.1 3.0 5.9 2.1 virginica 104 6.3 2.9 5.6 1.8 virginica 105 6.5 3.0 5.8 2.2 virginica 106 7.6 3.0 6.6 2.1 virginica The code above looks much better. The filtered data has been assigned to the object iris_virginica, so we now have a way to reference that data, and we could use this object to analyze the virginica plants exclusively. Variable Types R has several different variable types, and to manipulate your data it is good to be aware of them. 0.5, 2 # Numeric class TRUE, FALSE # Logical class &quot;hat&quot;, &quot;dog&quot; # Character class 5L, 12L # Integer class (&quot;L&quot; stores the value as an integer) 1+0i, 2+4i # Complex class &quot;yes&quot;, &quot;no&quot; # Factor class (categorical variable; each level is a category) These variable types are the basic building blocks, and all values in R belong to one of them. You may have a situation where your data is imported as character but you’d like to change it to factor, or vice versa. You can easily do this with the as.factor() and as.character() functions, which we’ll talk more about in Chapter 5. y &lt;- c(1,2,3,4,5) y [1] 1 2 3 4 5 When you add multiple values together, it’s called concatenation. In the above example, numeric values were concatenated together and assigned to the object y The object y now refers to 5 values: 1, 2, 3, 4, 5. When we concatenate values together like this, we create a data type. Data Types R has many data types, but the only one we’ll worry about is the data frame. A data frame is usually the object that’s created when importing a data file into R. A data frame consists of columns and rows, where each column is the same length. Here’s an example of one of R’s built-in data frames called mtcars: head(mtcars) mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Functions and Arguments So far we’ve seen R as a calculator, created objects, and learned about variable types and data types. But how we we actually do things in R? That is, how do we manipulate data and run a statistical analysis? To do just about anything in R you use functions. What functions do in R is take a process that would normally be a hassle for the user and make it easier. For example, the mean() function. We’re all familiar with how the mean is calculated, and we could calculate this manually in R. If we wanted the mean of the numbers c(1, 3, 4, 4) we could simply sum the numbers and divide by n to get 3. But why do that when we can just use the mean() function? And that’s the basic idea of a function: to simplify things for us. The lm() function creates a linear model from our data, which again we could achieve the same result by manually performing many calculations, but this would be a time-consuming, arduous task, and using the lm() function greatly simplifies the process. Functions are great because they can simplify and streamline a process, but how do you make the function do exactly what you need to do in your analysis? Let’s take a look at the factor() function to get an indea of how to take advantage of functions and arguments. Factors are categorical variables, where each level is a category. Here is an example of character data that’s been converted to a factor with the factor() function: y &lt;- c(&quot;cat&quot;, &quot;dog&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;dog&quot;, &quot;cat&quot;, &quot;dog&quot;) y &lt;- factor(y) # y is converted to a factor with 2 levels y [1] cat dog cat cat dog cat dog Levels: cat dog In this example, two levels are created from the data: cat and dog. Let’s slighly modify this example and say that data was entered incorrectly into a column, so the column looks like this: y &lt;- c(&quot;cat&quot;, &quot;dg&quot;, &quot;cat&quot;, &quot;cart&quot;, &quot;dog&quot;, &quot;cat&quot;, &quot;dog&quot;) y &lt;- factor(y) y [1] cat dg cat cart dog cat dog Levels: cart cat dg dog Because of the typos, we now have 4 levels–cat, dg, cart, dog– and that’s clearly not what we want. To make the most of the factor() function, we can make use of its arguments, which allows us to have greater control over what the function does and how it manipulates the data. We could ignore the typos by using the levels argument, which is a way of specifying how many levels we’re supposed to have for the data: y &lt;- c(&quot;cat&quot;, &quot;dg&quot;, &quot;cat&quot;, &quot;cart&quot;, &quot;dog&quot;, &quot;cat&quot;, &quot;dog&quot;) y &lt;- factor(y, levels = c(&quot;cat&quot;, &quot;dog&quot;)) y [1] cat &lt;NA&gt; cat &lt;NA&gt; dog cat dog Levels: cat dog We’re now back to two levels, and the typos were treated as NA. Now let’s say we wanted to recode cat as 0 and dog as 1. We could use the labels argument, which creates a new label for the corresponding level (in order): y &lt;- c(&quot;cat&quot;, &quot;dg&quot;, &quot;cat&quot;, &quot;cart&quot;, &quot;dog&quot;, &quot;cat&quot;, &quot;dog&quot;) y &lt;- factor(y, levels = c(&quot;cat&quot;, &quot;dog&quot;), labels = c(0, 1)) y [1] 0 &lt;NA&gt; 0 &lt;NA&gt; 1 0 1 Levels: 0 1 By using factor()’s arguments we were able to get the function to do what we wanted it to do, not just what it does by default. This is what makes R so powerful! Example Now let’s look at a more complete example of functions and arguments with the lm() function. lm(formula, data, subset, weights, na.action, method = &quot;qr&quot;, model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, contrasts = NULL, offset, ...) Above is the lm() function used for fitting linear models. The function has many arguments, but most of the arguments have default values; what this means is that you do not need to assign a value to that argument in order for the function to work. For example, in this function the default method argument is set to qr: method = &quot;qr&quot;. This means that when you use the lm() function, the method will be set to qr even if you don’t explicitly set it to qr; hence, qr is the default (which is referring to QR Decomposition, in case you were curious). In addition to arguments that have default values, there are also arguments which are optional. In the lm() function above, subset, weights, na.action, and offset are all optional arguments. Unsurpringly, this means that these arguments do not need to be used, but they can be. We can now see why the code below is valid, even though there are many arguments that we didn’t specify. lm(formula = mpg ~ hp, data = mtcars) We can also see why this code below is valid. The subset argument is optional, and here we used it to specify that we only want to include the first 10 observations in our model. lm(formula = mpg ~ hp, data = mtcars, subset = c(1:10)) But how do I know what the arguments are for a given function, what they do, which arguments have default values, which ones are optional, and which ones I need to specify? This is where the documentation comes in handy. You can type a question mark in front of the function you’d like to learn more about (?factor). If you’re using RStudio, this will bring up the documentation page for that function under the help tab in the lower right pane, which will usually include a description, the arguments (and their descriptions), and example code showing how to use the function. You can also type the function into the search bar under the help tab on the lower right pane. Hopefully, though, we’ll provide enough example code throughout this booklet that you won’t need to concern yourself with all of these details. But, we can’t provide examples of everything for every situation, and you’ll almost certainly use functions that aren’t covered in this bookt. This is where having a basic understanding of these topics will come in handy. "],
["packages-and-libraries.html", "3 Packages and Libraries What are Packages? Installing Packages What’s a Library? Loading Packages", " 3 Packages and Libraries What are Packages? R has hundreds of useful functions, but sometimes you’ll want or need to use a function that’s not built into R. For example, R has several built-in functions for plotting data, such as the hist() function: hist(rnorm(100)) And that works fine if you want to quickly analyze your data, but that graph is certainly not publication quality. You could spruce up the plot by installing a package that contains functions for creating much more aesthetically pleasing plots, such as the ggplot2 package. library(ggplot2) set.seed(1) ggplot(tibble::tibble(rnorm = rnorm(100, mean = -1)), aes(x = rnorm)) + geom_density(tibble::tibble(rnorm = rnorm(100, mean = 1)), mapping = aes(x = rnorm), fill = &quot;blue&quot;, alpha = .7) + geom_density(fill = &quot;red&quot;, alpha = .7) + theme_bw() + labs(title = &quot;A Colorful Histogram Example&quot;) + xlab(&quot;Random Normal Distribution&quot;) + ylab(&quot;Density&quot;) + theme(panel.grid.minor.y = element_blank(), panel.grid.minor.x = element_blank(), panel.grid.major.y = element_blank(), panel.grid.major.x = element_blank(), text = element_text(size = 16, family = &quot;serif&quot;)) The ggplot2 package is simply a collection of R code and functions, created by an R user, that allows you to make highly customizable plots like the one above without too much difficulty. Installing Packages There are many packages that you can install to make data analysis easier. One package that we’ll use frequently throughout this book is the tidyverse package. The tidyverse package is actually a collection of packages bundled together– a meta-package. You can install the tidyverse with the following line of code: install.packages(&quot;tidyverse&quot;) # You only need to install a package once What’s a Library? Once you install a package it becomes part of your “library”. Your library is a collection of all the packages that are installed on your computer. If you click on the “packages” tab in the lower right pane, you can see a list of all the packages that are currently installed. This is your library. Notice how the header says “System Library”. Loading Packages Packages only need to be installed once, but they need to be loaded every time you start an R session. Loading a package puts it into the working memory; that way R knows you want to use those functions from those packages. You can load a package with the library() function: library(tidyverse) Running the code library(tidyverse) now allows you to use all of the functions that come bundled with the tidyverse package (which is a lot!). Pro tip: It’s best practice to load your desired package with the library() function at the very beginning of your R script; that way it’s loaded before the rest of your code is ran. You can check to see if you installed the tidyverse package and loaded it into your R session correctly by running the ggplot histogram code above. If you see the same plot in your R session, everything is working correctly! You might be wondering why the ggplot code worked when we loaded the tidyverse package and not the ggplot2 package. This is because the tidyverse is a meta-package, which includes the ggplot2 package within it (along with 7 other packages). So, if you get into the habit of loading the tidyverse meta-package at the beginning of your script, that will generally take care of everything for you, and you won’t need to worry about loading many (if any) other packages into your R session. "],
["reading-and-writing-data.html", "4 Reading and Writing Data Setting the Working Directory Reading Data Writing Data", " 4 Reading and Writing Data Setting the Working Directory Before you start importing files, you need to set the working directory so R looks for and saves files in the correct place. “Directory” is a synonym for folder, so ‘setting the working directory’ really just means we need to tell R which folder we’d like to use to import data from. You can determine your current working directory with the getwd() function: getwd() When you run this code, you should have a file path printed to your console. This file path is your current working directory, which means that’s where R is currently looking for files. More specifically, the last folder name listed in the file path is where R is looking for files. To change the working directory, you simply need to navigate to the folder you’d like to import files from in the lower right pane under the files tab. There are two folders shown in the example image above. If you’re following along with the folder we created for this book, which you can download here, then your folder setup should look the same. To import files from the data folder, you would click on the data folder and then click on the More dropdown arrow and click Set as Working Directory. After doing this, you should see something in your console similar to this: setwd(&quot;~/Your/File/Path&quot;), which indicates that your working directory has been changed to the listed file path. You are now ready to import data files from the data folder. Changing your working directory only temporarily changes it for your current R session. It does not permanently change it. It’s best practice to add the code setwd(&quot;~/Your/File/Path&quot;), which is the same code that’s printed to the console, to the beginning of your R script so that you do not have to manually set your working directory every time you open your R script. Note: The code in the rest of this chapter will only work if you are following along with the folder for this book and have correctly set the working directory to the data folder. Reading Data Once the working directory has correctly been set, importing data files is easy. There’s a file in the data folder named BMI_1.csv, and we can import it with the read.csv() function: data_csv &lt;- read.csv(&quot;BMI_1.csv&quot;) # Don&#39;t forget to assign the csv file to an object And if the BMI_1.csv was instead a .txt or .xlsx / .xls (excel) file, we could use the read.delim() and read_excel() functions, respectively: # txt file data_txt &lt;- read.delim(&quot;BMI_1.txt&quot;) # excel file data_xlsx &lt;- read_excel(&quot;BMI_1.xlsx&quot;) # You need to load the tidyverse package to use the read_excel() function read_excel() is a function that comes from the tidyverse package, which means you need to load the tidyverse into your R session in order to use it (library(tidyverse)). After you’ve imported your data you can view it with the head() function: head(data_xlsx) # A tibble: 6 x 2 height weight &lt;dbl&gt; &lt;dbl&gt; 1 68.5 155. 2 65.3 174. 3 62.1 138. 4 64.8 165. 5 70.1 149. 6 67.3 197. The three import functions above have many arguments that you can change if the data is not imported in the format you were expecting. For example, txt files can be formatted in different ways; sometimes the data is delimited with a tab, or it may be delimited with a semicolon. If your txt file is not separated by a tab, you can change the sep argument to indicate how it is separated (the default argument for sep is &quot;\\t&quot;, which means separated by a tab). Here’s an example where the txt file is not delimited by a tab, so it gets imported incorrectly: data &lt;- read.delim(&quot;BMI_2.txt&quot;) head(data) height.weight 1 68.5166834855604;154.681763861273 2 65.3186507959108;173.958957660404 3 62.0789448822327;138.211660043739 4 64.8491663241866;165.020083309111 5 70.1389452245124;148.630607472854 6 67.3137063327876;196.627466047489 We can fix this by and passing the sep argument a semicolon, which indicates that the data is not delimited with a tab, but instead with a semicolon: data &lt;- read.delim(&quot;BMI_2.txt&quot;, sep = &quot;;&quot;) head(data) height weight 1 68.51668 154.6818 2 65.31865 173.9590 3 62.07894 138.2117 4 64.84917 165.0201 5 70.13895 148.6306 6 67.31371 196.6275 As another example, you could read data from the third sheet of an excel file and skip the first 3 lines by specifying the sheet and skip arguments: read_excel(your_file, sheet = 3, skip = 3) Writing Data Writing files is just as easy as reading files. You can write .txt and .csv files with the following functions: # Write .txt file write.table(x = data, file = &quot;data.txt&quot;, sep = &quot;/t&quot;) # Write .csv file write.csv(x = data, file = &quot;data.csv&quot;) The first argument, x, is an R object, which is typically your dataset object. The second argument, file, is what you’d like to name the file you’re creating. The data file will be saved in whatever folder you’re currently in. "],
["formatting-data.html", "5 Formatting Data Merging Files Long Format Wide Format Missing Data Recoding Variables Changing Variable Types Rename Columns Change Column Order Data Transformation Dealing with Dates", " 5 Formatting Data This chapter will cover: missing data, merging data files, changing variable types, recoding varibles, data transformation and tidy data principles. The code in this chapter only works if you’re following along with the Github folder for this book (which you can download here), correctly set your working directory to the data folder (which you can learn how to do in Chapter 4), and run the code in the order it appears in this chapter. Merging Files Sometimes you might want to import multiple files and combine them into one dataset. This can be accomplished with the cbind() and rbind() functions, which are short for column bind and row bind. Let’s say you have three files that have the same column names and you want to combine them. data1 &lt;- read.csv(&quot;BMI_1.csv&quot;) dim(data1) data2 &lt;- read.csv(&quot;BMI_2.csv&quot;) dim(data2) data3 &lt;- read.csv(&quot;BMI_3.csv&quot;) dim(data3) newData &lt;- rbind(data1, data2, data3) dim(newData) [1] 20 2 [1] 20 2 [1] 20 2 [1] 60 2 As you can see the last printout shows the dimensions are 60 x 2, which means the three datasets were successfully combined. Let’s say you have two files with different column names and want to combine them side-by-side. For example, you might have a data file that contains subID, age and sex, and another file contains height and weight data. These columns can be added into one dataset with the cbind() function. subID, age, and sex dataset: data1 &lt;- read.csv(&quot;SubID_Age_Sex.csv&quot;) head(data1) subID age sex 1 1 30.68838 F 2 2 28.33384 M 3 3 33.65584 M 4 4 35.51969 M 5 5 32.43415 M 6 6 28.14712 F height and weight dataset: data2 &lt;- read.csv(&quot;BMI_1.csv&quot;) head(data2) height weight 1 68.51668 154.6818 2 65.31865 173.9590 3 62.07894 138.2117 4 64.84917 165.0201 5 70.13895 148.6306 6 67.31371 196.6275 Combind with the cbind() function: newData &lt;- cbind(data1, data2) head(newData) subID age sex height weight 1 1 30.68838 F 68.51668 154.6818 2 2 28.33384 M 65.31865 173.9590 3 3 33.65584 M 62.07894 138.2117 4 4 35.51969 M 64.84917 165.0201 5 5 32.43415 M 70.13895 148.6306 6 6 28.14712 F 67.31371 196.6275 Long Format Putting data in long format increases the number of rows and decreases the number of columns in a data frame. In the health sciences, this often means that one row corresponds to one observation (at one point in time). If your data is not in long format, you can change it to long format with the pivot_longer() function, which comes from the tidyverse package. Here’s an example of a research study where subjects had their VO2 max measured at four points in time, and it’s currently not in long format: data_VO2 &lt;- read.csv(&quot;data_VO2.csv&quot;) head(data_VO2) SubID Time1 Time2 Time3 Time4 1 1 36.72302 34.08948 41.50392 42.85447 2 2 28.09261 33.22172 39.22484 47.51721 3 3 25.32283 34.95023 38.91351 40.67717 4 4 31.87634 35.51951 38.05794 46.51975 5 5 30.98121 33.18143 41.16101 46.96758 6 6 31.83277 35.58868 33.92712 45.27417 We can convert the data_VO2.csv into long format with the pivot_longer() function: # Make sure the tidyverse package is loaded data_VO2_long &lt;- pivot_longer(data = data_VO2, cols = c(&quot;Time1&quot;, &quot;Time2&quot;, &quot;Time3&quot;, &quot;Time4&quot;), names_to = &quot;Time&quot;, values_to = &quot;VO2_max&quot;) head(data_VO2_long) # A tibble: 6 x 3 SubID Time VO2_max &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 Time1 36.7 2 1 Time2 34.1 3 1 Time3 41.5 4 1 Time4 42.9 5 2 Time1 28.1 6 2 Time2 33.2 Wide Format Putting data in wide format increases the number of columns in a data frame. In the health sciences, this often means that one row will contain multiple points in time; this is how the data_VO2.csv was formatted before we converted it to long format. We can now change it back into wide format with the pivot_wider() function, which also comes from the tidyverse package. # Make sure the tidyverse package is loaded data_VO2_wide &lt;- pivot_wider(data = data_VO2_long, names_from = &quot;Time&quot;, values_from = &quot;VO2_max&quot;) head(data_VO2_wide) # A tibble: 6 x 5 SubID Time1 Time2 Time3 Time4 &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 1 36.7 34.1 41.5 42.9 2 2 28.1 33.2 39.2 47.5 3 3 25.3 35.0 38.9 40.7 4 4 31.9 35.5 38.1 46.5 5 5 31.0 33.2 41.2 47.0 6 6 31.8 35.6 33.9 45.3 Missing Data Missing data can be handled in many different ways, and selecting the most appropriate method is beyond the scope of this book. Instead, we’ll only cover how to find and omit observations with missing data. First we’ll create a data frame in R that contains NA values: data &lt;- data.frame(Col1 = c(NA, 1, 21, 34, NA), Col2 = c(23, 34, 34, 12, 56), Col3 = c(NA, 2, 12, 43, 12)) data Col1 Col2 Col3 1 NA 23 NA 2 1 34 2 3 21 34 12 4 34 12 43 5 NA 56 12 You can use the is.na() function to assess if a value is missing in a data frame or not. For example: is.na(data) # Missing values in data frame Col1 Col2 Col3 [1,] TRUE FALSE TRUE [2,] FALSE FALSE FALSE [3,] FALSE FALSE FALSE [4,] FALSE FALSE FALSE [5,] TRUE FALSE FALSE What you get in return is TRUE and FALSE values. If the value is TRUE, that means there is an NA value in that location. This might not be particularly helpful, though, if you have a large data frame. Instead, it might be more useful to have the count of NA values returned. To do this, we could use the is.na() function wrapped inside of a sum() function: sum(is.na(data)) # Sum of missing values in data frame [1] 3 You might want to know how many NA values are in a specific column rather than the entire dataset. Selecting just one column from a data frame is a very common task, and one way you can do this is with the dollar sign, $: sum(is.na(data$Col1)) # Sum of missing values in Col1 [1] 2 A quick way to get the missing values for all columns of a data frame is with the colSums() function: colSums(is.na(data)) Col1 Col2 Col3 2 0 1 You can omit all missing values in a data frame with the na.omit() function: na.omit(data) Col1 Col2 Col3 2 1 34 2 3 21 34 12 4 34 12 43 The “opposite” of the na.omit() function would be finding and listing all the rows that do contain missing values, and that’s what the code below accomplishes: data[!complete.cases(data), ] Col1 Col2 Col3 1 NA 23 NA 5 NA 56 12 A couple things need to be explained first to understand the code above. First, brackets, [ ], are used to subset in R. For example, if you wanted the 5th row and 3rd column returned from a data frame, you could do this by subsetting the data frame like so: data[5,3]. The first item within the bracket refers to the row number, and the second number refers to the column number. If you don’t put any numbers within the brackets, data[,], then everything is selected (the entire data frame). Going back to the example above, you can see that the data is being subsetted by the rows. complete.cases() is a function similar to na.omit(), where the NA values are not included. Notice that there is an exclamation point, !, in front of the function. This means that instead of returning the cases that are complete, what’s being returned is the cases that are not complete from the data frame. So, we’re subsetting data by its rows, where the incomplete cases are returned, and all the columns are selected. If that was confusing, that’s okay! If there’s one thing to take away from this, it’s that you can use the brackets for subsetting. Note: You might have noticed that you can select a column in R like this data$Col3, and also like this data[ ,3]. There are almost always multiple ways to accomplish something in R, and both ways work equally well. Let’s try computing the mean for the first column of the data object which contains missing values: mean(data$Col1) [1] NA As you can see, NA is returned. This is because Col1 contains missing values. Luckily the mean() function has an na.rm argument, which stands for ‘not available, remove’. We can set this argument to TRUE, so that missing values will be removed when computing the mean: mean(data$Col1, na.rm = TRUE) [1] 18.66667 Mean imputation Rather than omitting missing values from analysis with the na.omit() function, you could perform mean inputation. df &lt;- data.frame(col1 = c(2.5, 4.2, 3.2, NA)) df$col1[is.na(df$col)] &lt;- mean(df$col, na.rm = TRUE) df col1 1 2.5 2 4.2 3 3.2 4 3.3 In the code above, a data frame is created that has one column, and the fourth value is an NA. The NA is then replaced with the average of the other three numbers. We are not suggesting that you use mean imputation when your dataset contains missing values, but merely demonstrating how this can be done in R. Recoding Variables One of the easiest ways to recode/fix factors in R is with the factor() function. We’ll use the SubID_Age_Sex.csv dataset that was used earlier: SubID_Age_Sex &lt;- read.csv(&quot;SubID_Age_Sex.csv&quot;) head(SubID_Age_Sex) subID age sex 1 1 30.68838 F 2 2 28.33384 M 3 3 33.65584 M 4 4 35.51969 M 5 5 32.43415 M 6 6 28.14712 F For the factor() function, the first argument, x, is the column that should be selected, which in this case is sex. Again, we can use the dollar sign $ to select a specific column from a dataset. The second argument, levels, is the levels that should be included, and the third argument, labels, is the labels that should be assigned to each level, respectively. SubID_Age_Sex$sex &lt;- factor(x = SubID_Age_Sex$sex, levels = c(&quot;M&quot;,&quot;F&quot;), labels = c(0,1)) head(SubID_Age_Sex) subID age sex 1 1 30.68838 1 2 2 28.33384 0 3 3 33.65584 0 4 4 35.51969 0 5 5 32.43415 0 6 6 28.14712 1 Let’s take a look at a recoding example that’s slighly more involved. We’ll use the data_VO2.csv dataset used earlier. data_VO2 &lt;- read.csv(&quot;data_VO2_long.csv&quot;) head(data_VO2) SubID Time VO2_max 1 1 Time1 24.75065 2 1 Time2 35.03364 3 1 Time3 42.41792 4 1 Time4 46.61252 5 2 Time1 31.29356 6 2 Time2 29.43164 And we’ll add a column of the subject’s sex: data_VO2$Sex &lt;- rep(c(rep(&quot;M&quot;, 4), rep(&quot;F&quot;, 4)), 10) head(data_VO2) SubID Time VO2_max Sex 1 1 Time1 24.75065 M 2 1 Time2 35.03364 M 3 1 Time3 42.41792 M 4 1 Time4 46.61252 M 5 2 Time1 31.29356 F 6 2 Time2 29.43164 F Rather than having VO2max as continuous data, we’ll change it to categorical data: poor, fair, good, excellent. The catch, however, is that the classification will partially depend on whether the subject was a male or female (it also depends on age, but we’ll assume everyone in the study was 30 years old). The easiest way to do this is with the ifelse() function, and we’ll also use several functions from the tidyverse package. First, we need to filter the data so that only males or females are included in the dataset, but not both. We can do this with the filter() function from the tidyverse package. We’ll also need to create a new column to store the data in, and one easy way to do this is with the mutate() function from the tidyverse package. data_VO2_F &lt;- filter(data_VO2, Sex == &quot;F&quot;) data_VO2_F &lt;- mutate(data_VO2, VO2_max_cat = ifelse(VO2_max &lt; 22.8, &quot;Very Poor&quot;, ifelse(VO2_max &gt;= 22.8 &amp; VO2_max &lt;= 26.9, &quot;Poor&quot;, ifelse(VO2_max &gt;= 27.0 &amp; VO2_max &lt;= 31.4, &quot;Fair&quot;, ifelse(VO2_max &gt;= 31.5 &amp; VO2_max &lt;= 35.6, &quot;Good&quot;, ifelse(VO2_max &gt;= 35.7 &amp; VO2_max &lt;= 40.0, &quot;Excellent&quot;, &quot;Superior&quot;)))))) head(data_VO2_F) SubID Time VO2_max Sex VO2_max_cat 1 1 Time1 24.75065 M Poor 2 1 Time2 35.03364 M Good 3 1 Time3 42.41792 M Superior 4 1 Time4 46.61252 M Superior 5 2 Time1 31.29356 F Fair 6 2 Time2 29.43164 F Fair In the code above, the data was filtered to only include females. Notice that there are two equals signs == within the filter() function. If you only add one equals sign here you’ll get an error, and errors like this can be very difficult to find! After filtering, the data frame was assigned to the object data_VO2_F. Next, the mutate() function was used to create a new column called VO2_max_cat (cat for category). Then, the ifelse() function was used to assign a category based on the subject’s VO2_max. The first line reads, “If the VO2_max is less than 22.8, assign it the value”Very Poor“.” The last category, Superior, is assigned if the value does not meet any of the other conditions, which in this case is all values greater than 40.0. Now we can repeat the same process for males: data_VO2_M &lt;- filter(data_VO2, Sex == &quot;M&quot;) data_VO2_M &lt;- mutate(data_VO2_M, VO2_max_cat = ifelse(VO2_max &lt; 31.5, &quot;Very Poor&quot;, ifelse(VO2_max &gt;= 31.5 &amp; VO2_max &lt;= 35.4, &quot;Poor&quot;, ifelse(VO2_max &gt;= 35.5 &amp; VO2_max &lt;= 40.9, &quot;Fair&quot;, ifelse(VO2_max &gt;= 41.0 &amp; VO2_max &lt;= 44.9, &quot;Good&quot;, ifelse(VO2_max &gt;= 45.0 &amp; VO2_max &lt;= 49.4, &quot;Excellent&quot;, &quot;Superior&quot;)))))) head(data_VO2_M) SubID Time VO2_max Sex VO2_max_cat 1 1 Time1 24.75065 M Very Poor 2 1 Time2 35.03364 M Poor 3 1 Time3 42.41792 M Good 4 1 Time4 46.61252 M Excellent 5 3 Time1 28.31473 M Very Poor 6 3 Time2 32.42022 M Poor If you wanted the data frames to be combined back into one data frame that included both males and females, you could use the rbind() function. You might want to recode certain values as NA if you know the values are either impossible or very unrealistic. Here’s an example were Age data is collected, and values less than 0 or greater than 120 are recoded as NA. Notice the vertical bar in the code. The vertical bar (also called the pipe) means or. So the code below reads, “If Age is less than 0 or greater than 120, assign it the value NA.” df &lt;- data.frame(Age = c(1546, 43, 23, 56, -64)) df$Age[df$Age &lt; 0 | df$Age &gt; 120] &lt;- NA df Age 1 NA 2 43 3 23 4 56 5 NA Changing Variable Types class() as.numeric() as.integer() as.character() as.factor() Rename Columns colnames() Change Column Order # Reorder by column name data &lt;- data[c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)] # Reorder by column index df[,c(1,2,3,4)] Data Transformation select() filter() mutate() arrange() group_by() summarise() Dealing with Dates "],
["describing-and-visualizing-data.html", "6 Describing and Visualizing Data Viewing Data Data Summaries Visualizing Data", " 6 Describing and Visualizing Data Viewing Data # Using the view button dim() nrow() ncol() str() head() tail() as.tibble() row.names() names() colnames() Data Summaries mean() sd() range() is.na() sum(is.na()) colSums(is.na()) summary() xtabs() table() apply(array, margin, ...) Visualizing Data plot() abline() hist() boxplot() fourfoldplot() "],
["simple-regression.html", "7 Simple Regression Step 1: Importing Step 2: Viewing Step 3: Formatting Step 4: Modelling", " 7 Simple Regression In this chapter we’ll use the lm() function for fitting a simple regression model with one continuous predictor. This will be a quick and simple example that assumes the data is in tidy format and is ready for analysis. If this is not the case for you, you can take a look at Chapter 4 which covers basic data formatting. Step 1: Importing # Import ## Set your working directory to the data folder getwd() setwd() list.files() data &lt;- read.csv() ## You can use the read.csv() arguments to make importing adjustments ## Bind together files if needed cbind() # Column bind rbind() # Row bind ## Long and Wide formatting Step 2: Viewing # View head() str() summary() hist() plot() is.na() mean() sd() Let’s see what it looks like: head(iris) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa As you can see, it’s a very simple datasest consisting of sepal lengths and widths, and petal lengths and widths for several (three) species of plants. Now let’s use the str function to see the structure of the dataset: str(iris) &#39;data.frame&#39;: 150 obs. of 5 variables: $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... This tells us a lot of good information. We have a data-frame, we know the dimensions, and we know the data types of the columns. The next step is typically formatting the data, but obviously there’s nothing to format here. So we’ll go straight to the modelling step. Step 3: Formatting Step 4: Modelling The lm() Function lm(formula, data, subset, weights, na.action, method = &quot;qr&quot;, model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, contrasts = NULL, offset, ...) The lm() (linear model) function is used for fitting linear models. Notice that there are many arguments for this function, but the formula argument is the only argument that needs to be specified. If you’d like to learn more about functions and arguments, please take a look at Chapter 2 which covers basic programming concepts, including functions and arguments. Let’s take a look at how we can use the lm() function to make two models with the same variables using a simple regression: the untransformed linear model and a mean-centered model. For both models we’ll use Sepal Length as the dependent variable and Sepal Width as the independent variable. Model 1: Untransformed \\[y_i\\ =\\ \\beta_0\\ +\\ \\beta_1\\left(x_i\\right)\\ +\\ e_i\\] The equation above represents the untransformed, simple regression model with one continuous predictor. Let’s implement this model with the lm() function. The dependent variable is listed first, followed by a tilda, ~, and then the independent variable(s). lm(formula = Sepal.Length ~ Sepal.Width, data = iris) Call: lm(formula = Sepal.Length ~ Sepal.Width, data = iris) Coefficients: (Intercept) Sepal.Width 6.5262 -0.2234 The function prints out the slope and intercept for the model. We could then use the slope and intercept to create a plot with an abline: plot(iris$Sepal.Width, iris$Sepal.Length) abline(6.5262, -0.2234, col = &quot;red&quot;) The correlation looks weak, and it likely isn’t significant, but how can we be sure? The lm() function printed the coefficients but did not provide information about the R-squared or significance. To see this information, we need to save the model as an object, and then print the summary of the model, like so: my_model &lt;- lm(formula = Sepal.Length ~ Sepal.Width, data = iris) summary(my_model) Call: lm(formula = Sepal.Length ~ Sepal.Width, data = iris) Residuals: Min 1Q Median 3Q Max -1.5561 -0.6333 -0.1120 0.5579 2.2226 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.5262 0.4789 13.63 &lt;2e-16 *** Sepal.Width -0.2234 0.1551 -1.44 0.152 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.8251 on 148 degrees of freedom Multiple R-squared: 0.01382, Adjusted R-squared: 0.007159 F-statistic: 2.074 on 1 and 148 DF, p-value: 0.1519 Now we have a nice summary print-out which includes the F-statistic, Residuals, R-squared, p-value, and more. What’s also nice is we can now use the plot function on the my_model object that we just created to view Residuals vs Fitted, Normal Q-Q, Scale-Location and Residuals vs Leverage plots. par(mfrow = c(2,2)) # this function prints the graphs as a 2x2 grid plot(my_model) What else can we do with the my_model object? Let’s take a look at the object’s attributes: attributes(my_model) $names [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; [5] &quot;fitted.values&quot; &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; [9] &quot;xlevels&quot; &quot;call&quot; &quot;terms&quot; &quot;model&quot; $class [1] &quot;lm&quot; The model’s attributes can be accessed by using a dollar sign, $. For example, here’s a printout of the first 5 residuals of our model: my_model$residuals[1:5] 1 2 3 4 5 -0.6444588 -0.9561394 -1.1114672 -1.2338033 -0.7221227 Model 2: Mean-Centered \\[y_i=\\beta_0+\\beta_1\\left(x_i\\ -\\ \\overline{x}\\right)\\ +\\ e_i\\] In this example we’ll use the same variables as before but this time we’ll mean-center the independent/predictor variable. First, we create a column that consists of the sepal width mean, which is 3.06. Since there are 150 rows in the iris dataset, that means we are creating a column that has the value 3.06 repeated 150 times. This value is then saved into the column SW_mean; that’s what the first line of code in the code chunk below is doing. In the second line of code, each sepal width value is subtracted from the sepal width mean column, which is then stored in a new column called SW_mean_center. # create a column that consists of the mean sepal width value iris$SW_mean &lt;- mean(iris$Sepal.Width) # subtract sepal width column from mean column iris$SW_mean_center &lt;- iris$Sepal.Width - iris$SW_mean Let’s see what it looks like. plot(iris$SW_mean_center, iris$Sepal.Length) abline(lm(iris$Sepal.Length ~ iris$SW_mean_center), col = &quot;red&quot;) We can now use this mean-centered column as the dependent variable. lm(formula = Sepal.Length ~ SW_mean_center, data = iris) Call: lm(formula = Sepal.Length ~ SW_mean_center, data = iris) Coefficients: (Intercept) SW_mean_center 5.8433 -0.2234 "],
["multiple-regression.html", "8 Multiple Regression The lm() Function", " 8 Multiple Regression The lm() Function lm(formula, data, subset, weights, na.action, method = &quot;qr&quot;, model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, contrasts = NULL, offset, ...) The lm() (linear model) function is used for fitting linear models. This is the function we’ll be using for this chapter. Notice that there are many arguments for this function, but the formula argument is the only argument that needs to be specified. If you’d like to learn more about functions and arguments, please have a look at Chapter 2 which covers basic programming concepts, including functions and arguments. "],
["quick-example.html", "Quick Example", " Quick Example In this example we’ll use the lm() function for fitting a multiple regression model with two continuous predictors. This will be a quick and simple example that assumes the data is in tidy format and is ready for analysis. If this is not the case for you, you can take a look at Chapter 4 which covers basic data formatting. Model 1 \\[y_i\\ =\\ \\beta_0\\ +\\ \\beta_1\\left(x_i\\right)\\ +\\ \\beta_2\\left(x_i\\right)\\ +\\ e_i\\] "],
["comprehensive-example.html", "9 Comprehensive Example", " 9 Comprehensive Example # Import ## Set your working directory to the data folder getwd() setwd() list.files() data &lt;- read.csv() ## You can use the read.csv() arguments to make importing adjustments ## Bind together files if needed cbind() # Column bind rbind() # Row bind ## Long and Wide formatting # View head() str() summary() hist() plot() is.na() mean() sd() # Format # Model lm() "]
]
